Here are the concise steps required to use a Nomic embedding model (e.g., `nomic-embed-text`) via Ollama for your AI search feature:

**Prerequisites (Ensure these are in place first):**

1.  **PostgreSQL with `pgvector` Extension:**

      * Have a PostgreSQL database running.
      * **Crucially**, ensure the `pgvector` extension is installed and enabled in your `pokemon_db` database (run `CREATE EXTENSION vector;` if not already done).

2.  **Ollama Installed and Running:**

      * Download and install the Ollama client from [ollama.com](https://ollama.com/).
      * Start the Ollama server (it usually runs in the background after installation).

**Steps for Spring AI Integration:**

1.  **Pull the Nomic Embedding Model with Ollama:**

      * Open your terminal/command prompt.
      * Execute the Ollama command to download the Nomic embedding model:
        ```bash
        ollama pull nomic-embed-text
        ```
        This downloads the model and makes it available to Ollama's local API.

2.  **Add Spring AI Dependencies:**

      * In your Spring Boot project's `pom.xml` (or `build.gradle`), ensure you have:
          * The `spring-ai-bom` for consistent versioning.
          * `spring-ai-ollama` for integrating with Ollama.
          * `spring-ai-pgvector-store` for your vector database.
          * Your standard Spring Boot web and JPA dependencies.

    <!-- end list -->

    ```xml
    <dependencies>
        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-bom</artifactId>
            <version>1.0.0-M1</version> <type>pom</type>
            <scope>import</scope>
        </dependency>

        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-ollama</artifactId>
            <version>1.0.0-M1</version> </dependency>

        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-pgvector-store</artifactId>
            <version>1.0.0-M1</version> </dependency>
    </dependencies>
    ```

3.  **Configure `application.properties`:**

      * Set up your PostgreSQL connection details.
      * Configure Spring AI to use Ollama and specify the `nomic-embed-text` model for embeddings.

    <!-- end list -->

    ```properties
    # PostgreSQL Database Configuration
    spring.datasource.url=jdbc:postgresql://localhost:5432/pokemon_db
    spring.datasource.username=your_username
    spring.datasource.password=your_password
    spring.datasource.driver-class-name=org.postgresql.Driver
    spring.jpa.hibernate.ddl-auto=update # Or create
    spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

    # Spring AI Ollama Configuration
    spring.ai.ollama.base-url=http://localhost:11434 # Default Ollama API URL
    spring.ai.ollama.embedding.options.model=nomic-embed-text # Specify the Nomic embedding model
    ```

4.  **Implement Pokémon Embedding Service:**

      * Create a `@Service` class (e.g., `PokemonEmbeddingService`) that will:
          * `@Autowired` `VectorStore` (which will be `PgVectorStore` automatically) and `EmbeddingClient` (which will be `OllamaEmbeddingClient` automatically).
          * Have an `@PostConstruct` method to, on application startup, retrieve all your Pokémon data.
          * For each Pokémon, create a `Document` object using its combined descriptive content (e.g., `pokemon.getEmbeddableContent()`). Make sure to include relevant metadata like `pokemon_id` in the `Document`'s metadata for easy retrieval. Optionally, set the `Document`'s ID to `pokemon.getId().toString()`.
          * Call `vectorStore.add(List<Document>)` to embed the Pokémon data and store it in your PostgreSQL `pgvector` table.
          * (Crucial for CRUD) Implement methods to `addOrUpdatePokemonInVectorStore(Pokemon)` and `deletePokemonFromVectorStore(Long pokemonId)` that you call from your main CRUD service whenever a Pokémon is added, updated, or soft-deleted.

5.  **Create REST Controller for Semantic Search:**

      * Create a `@RestController` (e.g., `PokemonSearchController`).
      * `@Autowired` the `VectorStore` and your `PokemonRepository`.
      * Create a `@GetMapping` endpoint (e.g., `/pokemon/semantic-search`) that accepts a `query` parameter.
      * Inside the endpoint, create a `SearchRequest` with the user's query and desired `topK` results.
      * Call `vectorStore.similaritySearch(searchRequest)` to get a list of relevant `Document` objects.
      * Extract the `pokemon_id` from the metadata of these `Document`s.
      * Use your `PokemonRepository` to fetch the full `Pokemon` entities from your main database based on these IDs.
      * Return the list of `Pokemon` objects.

By following these steps, you'll have a fully functional, free, and local semantic search feature powered by a Nomic embedding model (via Ollama) and PostgreSQL with `pgvector` in your Spring Boot application.
